{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement:** Classify emails as spam or not spam using binary classification. The two states are:\n",
    "a) Normal State – Not Spam (0)\n",
    "b) Abnormal State – Spam (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "1. Pre-process the dataset.\n",
    "2. Implement K-Nearest Neighbors (KNN) and Support Vector Machine (SVM) for classification.\n",
    "3. Analyze and compare the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import necessary libraries for data manipulation, visualization, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Columns: 3002 entries, Email No. to Prediction\n",
      "dtypes: int64(3001), object(1)\n",
      "memory usage: 118.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and non-null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email No.     0\n",
       "the           0\n",
       "to            0\n",
       "ect           0\n",
       "and           0\n",
       "             ..\n",
       "military      0\n",
       "allowing      0\n",
       "ff            0\n",
       "dry           0\n",
       "Prediction    0\n",
       "Length: 3002, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Clean Data\n",
    "Drop unnecessary columns like RowNumber, CustomerId, and Surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Email No.'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define Input (X) and Output (y) Features\n",
    "Separate the dataset into features (X) and the target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Prediction' is the target column (0 for Not Spam, 1 for Spam)\n",
    "X = df.drop('Prediction', axis=1)\n",
    "y = df['Prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Train-Test Split\n",
    "Split the data into training and testing sets (80% train, 20% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: K-Nearest Neighbors (KNN)\n",
    "Train and predict using KNN with n_neighbors=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Support Vector Machine (SVM)\n",
    "Train and predict using SVM with a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using kernel='linear' as it is often good for high-dimensional text data\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Models\n",
    "Compare the performance of both models using standard classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: KNN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- K-Nearest Neighbors ---\n",
      "Accuracy: 0.9594202898550724\n",
      "\n",
      "Confusion Matrix:\n",
      "[[645  94]\n",
      " [ 48 248]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       739\n",
      "           1       0.73      0.84      0.78       296\n",
      "\n",
      "    accuracy                           0.86      1035\n",
      "   macro avg       0.83      0.86      0.84      1035\n",
      "weighted avg       0.87      0.86      0.87      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--- K-Nearest Neighbors ---')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_svm)}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: SVM Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Support Vector Machine ---\n",
      "Accuracy: 0.9594202898550724\n",
      "\n",
      "Confusion Matrix:\n",
      "[[715  24]\n",
      " [ 18 278]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       739\n",
      "           1       0.92      0.94      0.93       296\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--- Support Vector Machine ---')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_svm)}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN) Accuracy: 0.9594202898550724\n",
      "Support Vector Machine (SVM) Accuracy: 0.9594202898550724\n"
     ]
    }
   ],
   "source": [
    "print(f'K-Nearest Neighbors (KNN) Accuracy: {accuracy_score(y_test, y_pred_svm)}')\n",
    "print(f'Support Vector Machine (SVM) Accuracy: {accuracy_score(y_test, y_pred_svm)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Both models performed well on the dataset. The Support Vector Machine (SVM) classifier achieved a slightly higher accuracy than the K-Nearest Neighbors (KNN) classifier. Based on the classification reports, SVM also shows strong precision and recall for both spam and non-spam classes, making it the more robust model for this specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes For Viva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm and Metrics Explanation\n",
    "\n",
    "**K-Nearest Neighbors (KNN)**\n",
    "\n",
    "Definition: A supervised, non-parametric, and \"lazy learning\" algorithm used for both classification and regression. For classification, it predicts the class of a new data point based on the majority class of its 'k' nearest neighbors in the feature space.\n",
    "\n",
    "Important Info:\n",
    "\n",
    "- Lazy Learning: It does not build a general model during training; it stores the entire training dataset. The computation occurs at prediction time.\n",
    "\n",
    "- Choice of 'k': The value of 'k' is critical. A small 'k' can be sensitive to noise, while a large 'k' can be computationally expensive and may oversmooth the decision boundary.\n",
    "\n",
    "- Distance Metric: Relies on a distance metric, typically Euclidean distance.\n",
    "\n",
    "- Scaling: Very sensitive to the scale of features. Features with larger ranges can dominate the distance calculation, so feature scaling (e.g., standardization) is almost always required.\n",
    "\n",
    "Formula (Euclidean Distance):\n",
    "\n",
    "\n",
    "$$d(p, q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}$$\n",
    "\n",
    "- $p, q$: Two data points\n",
    "\n",
    "- $n$: Number of features\n",
    "\n",
    "**Support Vector Machine (SVM)**\n",
    "\n",
    "Definition: A supervised learning algorithm that finds an optimal \"hyperplane\" that best separates data points into different classes. The best hyperplane is the one that maximizes the \"margin\" (the distance) between the hyperplane and the nearest data points (called \"support vectors\").\n",
    "\n",
    "Important Info:\n",
    "\n",
    "- Kernel Trick: Can efficiently perform non-linear classification by mapping data to a higher-dimensional space. Common kernels are 'linear', 'poly', and 'rbf' (Radial Basis Function).\n",
    "\n",
    "- High-Dimensional Data: Very effective in high-dimensional spaces, making it suitable for tasks like text classification (where each word can be a feature).\n",
    "\n",
    "- Support Vectors: These are the data points closest to the hyperplane. They are the only points that influence the position and orientation of the hyperplane.\n",
    "\n",
    "**Evaluation Metrics for Classification**\n",
    "\n",
    "**Confusion Matrix**\n",
    "\n",
    "Definition: A table used to visualize the performance of a classifier. It shows the number of correct and incorrect predictions for each class.\n",
    "\n",
    "- True Positive (TP): Actual: 1, Predicted: 1\n",
    "\n",
    "- True Negative (TN): Actual: 0, Predicted: 0\n",
    "\n",
    "- False Positive (FP): Actual: 0, Predicted: 1 (Type I Error)\n",
    "\n",
    "- False Negative (FN): Actual: 1, Predicted: 0 (Type II Error)\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "Definition: The ratio of correctly predicted instances to the total number of instances.\n",
    "\n",
    "Formula:\n",
    "\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "**Precision**\n",
    "\n",
    "Definition: Measures the accuracy of positive predictions. Answers the question: \"Of all the emails the model predicted as spam, what fraction was actually spam?\"\n",
    "\n",
    "Formula:\n",
    "\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "\n",
    "Definition: Measures the model's ability to find all positive instances. Answers the question: \"Of all the actual spam emails, what fraction did the model correctly identify as spam?\"\n",
    "\n",
    "Formula:\n",
    "\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**F1-Score**\n",
    "\n",
    "Definition: The harmonic mean of Precision and Recall. It provides a single score that balances both metrics, which is useful when classes are imbalanced.\n",
    "\n",
    "Formula:\n",
    "\n",
    "\n",
    "$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
    "\n",
    "**Potential Viva Questions**\n",
    "\n",
    "Q1: What is \"lazy learning\" and why is KNN called that?  \n",
    "A: \"Lazy learning\" (or instance-based learning) is a method where the model does not build a general internal model during the training phase. It simply stores the training data. The main computational work is delayed until a prediction is requested. KNN is called this because it just stores all training points and finds the 'k' nearest neighbors only when it needs to make a new prediction.\n",
    "\n",
    "Q2: In spam detection, is a False Positive or a False Negative a worse error?  \n",
    "A: A False Positive (classifying a real email as spam) is generally considered much worse. This means a user might miss an important email (e.g., from their bank, job, or family) because it was incorrectly sent to the spam folder. A False Negative (classifying a spam email as real) is just an annoyance that the user has to delete manually.\n",
    "\n",
    "Q3: What are \"support vectors\" in SVM?  \n",
    "A: Support vectors are the data points from each class that are closest to the decision boundary (hyperplane). They are the most difficult points to classify and are the only points that \"support\" or define the optimal position of the hyperplane. If any other (non-support vector) point were removed, the hyperplane would not change.\n",
    "\n",
    "Q4: Why might you need to scale your data before using KNN?  \n",
    "A: KNN works by calculating distances between data points. If one feature has a very large scale (e.g., word count from 0-1000) and another has a small scale (e.g., 0-1), the feature with the larger scale will completely dominate the distance calculation. This makes the smaller-scale feature almost irrelevant. Scaling (like standardization or normalization) brings all features to a comparable scale so that each feature contributes fairly to the distance.\n",
    "\n",
    "Q5: What is the \"kernel trick\" in SVM?  \n",
    "A: The kernel trick is a mathematical method that allows SVM to classify data that is not linearly separable. It takes the data and projects it into a higher-dimensional space where a linear hyperplane can be used to separate it. It does this efficiently by calculating the relationships between points in the higher dimension without ever actually transforming the data, which saves a lot of computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
